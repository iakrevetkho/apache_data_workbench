<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>

<configuration>

<!-- file system properties -->

  <property>
    <name>dfs.name.dir</name>
    <value>/var/local/hadoop/hdfs/name</value>
    <description>Determines where on the local filesystem the DFS name node
      should store the name table.  If this is a comma-delimited list
      of directories then the name table is replicated in all of the
      directories, for redundancy. </description>
    <final>true</final>
  </property>

  <property>
    <name>dfs.data.dir</name>
    <value>/var/local/hadoop/hdfs/data</value>
    <description>Determines where on the local filesystem an DFS data node
       should store its blocks.  If this is a comma-delimited
       list of directories, then data will be stored in all named
       directories, typically on different devices.
       Directories that do not exist are ignored.
    </description>
    <final>true</final>
  </property>

  <property>
    <name>dfs.datanode.address</name>
    <value>datanode:9866</value>
  </property>

  <property>
    <name>dfs.datanode.http.address</name>
    <value>datanode:9864</value>
  </property>

  <property>
    <name>dfs.namenode.http-address</name>
    <value>namenode:9870</value>
    <description>The name of the default file system.  Either the
       literal string "local" or a host:port for NDFS.
    </description>
  </property>

  <property>
    <name>dfs.http.address</name>
    <value>namenode:9870</value>
    <description>The name of the default file system.  Either the
       literal string "local" or a host:port for NDFS.
    </description>
  </property>

  <property>
    <name>dfs.datanode.ipc.address</name>
    <value>datanode:9867</value>
    <description>
      The datanode ipc server address and port.
      If the port is 0 then the server will start on a free port.
    </description>
  </property>

<!-- Permissions configuration -->

  <property>
    <name>dfs.permissions</name> 
    <value>false</value>
    <description>
      If "true", enable permission checking in HDFS.
    </description>
  </property>

  <property>
    <name>dfs.datanode.data.dir.perm</name>
    <value>700</value>
<description>The permissions that should be there on dfs.data.dir
directories. The datanode will not come up if the permissions are
different on existing dfs.data.dir directories. If the directories
don't exist, they will be created with this permission.</description>
  </property>

</configuration>